{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d353edbd",
   "metadata": {},
   "source": [
    "### MAIN MODEL BUILD/RUN\n",
    "\n",
    "#### This script is to build the Yolo Model to replicate the structure utilize for CholectT50 procedure in classifying instruments, phases, and sections. By employing YOLO, we require to have three things:\n",
    "1) Yaml File containing paths to train/test/validate\n",
    "2) Labels in COCO/YOLO Format\n",
    "3) Pretained Model to hyperparameter tune\n",
    "\n",
    "#### We will go over each kernel to explain the steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d7eaf",
   "metadata": {},
   "source": [
    "### STEPS:\n",
    "\n",
    "#### 1) Import Necessary Packages\n",
    "#### 2) Model Import/Preparation\n",
    "#### 3) Model Hyperparameter Tune Run\n",
    "#### 4) Retrieve Results/Winning Hyperparameters\n",
    "#### 5) Review Scoring/Possible Improvements\n",
    "#### 6) Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275ed89",
   "metadata": {},
   "source": [
    "##### IMPORTANT: TO RUN THIS SCRIPT DO THE FOLLOWING:\n",
    "\n",
    "1) Create conda environment as follows :\n",
    "    - conda create -n ECE579Proj python=3.10    \n",
    "    * (Python 3.10 is compatible with all packages in requirements.txt and torch version)\n",
    "1) Run the command : \n",
    "    - pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129 \n",
    "    * (VERIFY YOUR GPU DEVICE WITH 'nvidia-smi' TO SELECT CORRECT CUDA VERSION)\n",
    "2) Run the following command: \n",
    "    - pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5930e08",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648c681",
   "metadata": {},
   "source": [
    "#### 1) Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ea4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages for working with Model Requisites\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ultralytics import YOLO\n",
    "import yaml \n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d743a8",
   "metadata": {},
   "source": [
    "#### 2) Model Import / Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03abbd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt': 100% ━━━━━━━━━━━━ 5.3MB 22.7MB/s 0.2s.2s<0.2s\n"
     ]
    }
   ],
   "source": [
    "### Import an instance of YOLO Model, in this case we will utilize the new updated version, for October 2025,\n",
    "### titled YOLOv12\n",
    "\n",
    "model = YOLO('yolo12n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1eed64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n------> Standard data.yaml file structure <------\\n\\npath: .../datafolder\\ntrain: .../datafolder/images/train\\nval: .../datafolder/images/val\\ntest: .../datafolder/images/test\\n\\nnc: n      #-> Where n is any number of classes to utilize for train/val/test\\nnames: \\n    0: 'car'\\n    1: 'plane'\\n    2: .....\\n\\n    #-> Where the classes are assigned numerical values to pair up with\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To showcase how the data connects with Computer Vision modelssuch as YOLO\n",
    "### We will illustrate the structure of the YAML file as follows\n",
    "\n",
    "'''\n",
    "------> Standard data.yaml file structure <------\n",
    "\n",
    "path: .../datafolder\n",
    "train: .../datafolder/images/train\n",
    "val: .../datafolder/images/val\n",
    "test: .../datafolder/images/test\n",
    "\n",
    "nc: n      #-> Where n is any number of classes to utilize for train/val/test\n",
    "names: \n",
    "    0: 'car'\n",
    "    1: 'plane'\n",
    "    2: .....\n",
    "\n",
    "    #-> Where the classes are assigned numerical values to pair up with\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd57858",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The data isnt imported per se directly via any module, rather by YAML file to use in YOLO Model\n",
    "### So we would not utilize:\n",
    "\n",
    "#pd.read_csv\n",
    "\n",
    "#glob....\n",
    "\n",
    "### Or any version of those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62b425",
   "metadata": {},
   "source": [
    "#### 3) Model Hyperparameter Tune Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467fda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets set for the hyperparameters we which to tune\n",
    "### This will iteratively run the model with different \"settings\" to view which is the best fitted model\n",
    "\n",
    "hyperparameters = {\n",
    "    \"batch\": 16,\n",
    "    \"imgsz\": 1280,\n",
    "    \"epochs\": 50,\n",
    "    \"patience\": 20,\n",
    "    \"optimizer\": \"auto\",\n",
    "    \"cos_lr\": True,\n",
    "    \"rect\": True,\n",
    "    \"multi_scale\": False,\n",
    "    \"amp\": True\n",
    "}\n",
    "\n",
    "### Where the hyperparameters selected mean the following:\n",
    "\n",
    "#batch = batch size for images\n",
    "#imgsz = input size of images\n",
    "#epochs = number of iterations to run\n",
    "#patience = early stopping parameter\n",
    "#optimizer = if 'auto' let YOLO select best optimizer\n",
    "#cos_lr = cosine learning rate\n",
    "#rect = rectangular training parameter\n",
    "#multi_scale = Robustness parameter\n",
    "#amp = mix precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e098c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "current device index: 0\n",
      "current device name: NVIDIA GeForce RTX 5080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "### Lets verify if the GPU device is available to select\n",
    "### And showcase its index to use in our model\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "\n",
    "### Show the deviece name and index\n",
    "if torch.cuda.is_available():\n",
    "    print(\"current device index:\", torch.cuda.current_device())\n",
    "    print(\"current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "### With our hyperparameters of interest selected, we can build our hyperparameter run to iterate and find the optimal model\n",
    "\n",
    "model_result = model.tune(\n",
    "    data='[YAML FILE PATH HERE]',\n",
    "    device=\"0\",\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "### Save the tuned model\n",
    "\n",
    "tunedmodel_path = \"./MODEL_FILES/MODEL\"\n",
    "model.save(tunedmodel_path)\n",
    "print(f'Model tuning finished and stored/saved in : \\n{tunedmodel_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24613eb9",
   "metadata": {},
   "source": [
    "#### 4) Retrieve Results/Winning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will retrieve/load our model to view the hyperparameters solely \n",
    "### and review it\n",
    "'''\n",
    "[PLACEHOLDER]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc8486",
   "metadata": {},
   "source": [
    "#### 5) Review Scoring/Possible Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd7e7f",
   "metadata": {},
   "source": [
    "#### 6) Test Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE579Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
